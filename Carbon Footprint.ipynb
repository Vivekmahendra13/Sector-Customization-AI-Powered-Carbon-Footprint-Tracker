{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW5F6VdRThJE",
        "outputId": "d896d415-d4f8-42cf-8c30-7ae84af30336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygad in /usr/local/lib/python3.11/dist-packages (3.4.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pygad) (3.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pygad) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pygad) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pygad) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pygad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIO9GL7mByZ1",
        "outputId": "53ac6c44-5803-414b-c1c9-ad62b4895bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training for Agriculture sector...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for Agriculture: 0.002068\n",
            "\n",
            "Training for Industrial sector...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for Industrial: 0.001551\n",
            "\n",
            "Training for IT sector...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for IT: 0.001638\n",
            "\n",
            "Training for Manufacturing sector...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for Manufacturing: 0.001762\n",
            "\n",
            "Training for Residential sector...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for Residential: 0.001370\n",
            "\n",
            "Training for Transport sector...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for Transport: 0.002250\n",
            "\n",
            "Training for Power sector...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for Power: 0.001385\n",
            "\n",
            "Final Model Performance Per Sector:\n",
            "Agriculture: MSE = 0.002068\n",
            "Industrial: MSE = 0.001551\n",
            "IT: MSE = 0.001638\n",
            "Manufacturing: MSE = 0.001762\n",
            "Residential: MSE = 0.001370\n",
            "Transport: MSE = 0.002250\n",
            "Power: MSE = 0.001385\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "\n",
        "# List of sector-wise dataset files\n",
        "dataset_files = {\n",
        "    \"Agriculture\": \"agriculture_modified_data.csv\",\n",
        "    \"Industrial\": \"industrial_modified_data.csv\",\n",
        "    \"IT\": \"it_modified_data.csv\",\n",
        "    \"Manufacturing\": \"manufacturing_modified_data.csv\",\n",
        "    \"Residential\": \"residential_modified_data.csv\",\n",
        "    \"Transport\": \"transport_modified_data.csv\",\n",
        "    \"Power\": \"power_modified_data.csv\"\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "for sector, file_path in dataset_files.items():\n",
        "    try:\n",
        "        print(f\"\\nTraining for {sector} sector...\")\n",
        "\n",
        "        # Load dataset\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        if \"emissions_tons\" not in df.columns:\n",
        "            print(f\"Error: 'emissions_tons' column missing in {sector} dataset.\")\n",
        "            continue\n",
        "\n",
        "        # Define sector-specific features\n",
        "        sector_features = [col for col in df.columns if col != \"emissions_tons\"]\n",
        "\n",
        "        # Feature Scaling\n",
        "        scaler_X = MinMaxScaler()\n",
        "        scaler_y = MinMaxScaler()\n",
        "        X = scaler_X.fit_transform(df[sector_features])\n",
        "        y = scaler_y.fit_transform(df[\"emissions_tons\"].values.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # Save scalers\n",
        "        joblib.dump(scaler_X, f\"scaler_{sector}.pkl\")\n",
        "        joblib.dump(scaler_y, f\"scaler_y_{sector}.pkl\")\n",
        "\n",
        "        # Split dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # LSTM Model\n",
        "        X_train_lstm = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "        X_test_lstm = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "        lstm_model = Sequential([\n",
        "            tf.keras.layers.Input(shape=(X_train.shape[1], 1)),\n",
        "            LSTM(50, return_sequences=True),\n",
        "            Dropout(0.2),\n",
        "            LSTM(50),\n",
        "            Dense(1, activation=\"linear\")\n",
        "        ])\n",
        "        lstm_model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "        lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_data=(X_test_lstm, y_test), verbose=0)\n",
        "        lstm_model.save(f\"lstm_model_{sector}.h5\")\n",
        "\n",
        "        # XGBoost Model\n",
        "        xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100)\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "        joblib.dump(xgb_model, f\"xgb_model_{sector}.pkl\")\n",
        "\n",
        "        # Evaluate Model\n",
        "        y_pred = xgb_model.predict(X_test)\n",
        "        mse = np.mean((y_pred - y_test) ** 2)\n",
        "\n",
        "        print(f\"MSE for {sector}: {mse:.6f}\")\n",
        "        best_models[sector] = {\"XGBoost\": xgb_model, \"LSTM\": lstm_model, \"MSE\": mse}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {sector}: {e}\")\n",
        "\n",
        "# Final Results\n",
        "print(\"\\nFinal Model Performance Per Sector:\")\n",
        "for sector, model_info in best_models.items():\n",
        "    print(f\"{sector}: MSE = {model_info['MSE']:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTAiPgf8Byhl",
        "outputId": "ebdddd20-048c-42a2-da9e-4ba49dae840e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Agriculture sector...\n",
            "Expected features for Agriculture: ['fertilizer_use', 'water_consumption', 'machinery_hours', 'land_area']\n",
            "\n",
            "Processing Industrial sector...\n",
            "Expected features for Industrial: ['energy_use', 'production_volume', 'waste_generated', 'operating_hours']\n",
            "\n",
            "Processing IT sector...\n",
            "Expected features for IT: ['server_count', 'energy_use', 'data_transferred', 'cooling_load']\n",
            "\n",
            "Processing Manufacturing sector...\n",
            "Expected features for Manufacturing: ['raw_material_input', 'machine_runtime', 'output_quantity', 'energy_consumption']\n",
            "\n",
            "Processing Residential sector...\n",
            "Expected features for Residential: ['electricity_usage', 'gas_consumption', 'household_size', 'appliance_count']\n",
            "\n",
            "Processing Transport sector...\n",
            "Expected features for Transport: ['fuel_consumption', 'vehicle_count', 'distance_traveled', 'load_capacity']\n",
            "\n",
            "Processing Power sector...\n",
            "Expected features for Power: ['coal_used', 'gas_used', 'renewable_input', 'total_output']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n",
        "# List of sector-wise dataset files\n",
        "dataset_files = {\n",
        "    \"Agriculture\": \"agriculture_modified_data.csv\",\n",
        "    \"Industrial\": \"industrial_modified_data.csv\",\n",
        "    \"IT\": \"it_modified_data.csv\",\n",
        "    \"Manufacturing\": \"manufacturing_modified_data.csv\",\n",
        "    \"Residential\": \"residential_modified_data.csv\",\n",
        "    \"Transport\": \"transport_modified_data.csv\",\n",
        "    \"Power\": \"power_modified_data.csv\"\n",
        "}\n",
        "\n",
        "for sector, file_path in dataset_files.items():\n",
        "    try:\n",
        "        print(f\"\\nProcessing {sector} sector...\")\n",
        "\n",
        "        # Load dataset\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Drop non-numeric columns\n",
        "        drop_columns = [\"id\", \"timestamp\", \"user_type\", \"country\", \"sector\"]\n",
        "        df.drop(columns=[col for col in drop_columns if col in df.columns], errors='ignore', inplace=True)\n",
        "\n",
        "        if \"emissions_tons\" not in df.columns:\n",
        "            print(f\"Error processing {sector}: 'emissions_tons' column not found.\")\n",
        "            continue\n",
        "\n",
        "        # Fill missing values\n",
        "        df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "        # One-hot encoding for categorical variables\n",
        "        df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "        # Feature Scaling\n",
        "        scaler_X = MinMaxScaler()\n",
        "        scaler_y = MinMaxScaler()\n",
        "\n",
        "        features = [col for col in df.columns if col != \"emissions_tons\"]\n",
        "        X = scaler_X.fit_transform(df[features])\n",
        "        y = scaler_y.fit_transform(df[\"emissions_tons\"].values.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # Split dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train XGBoost Model\n",
        "        xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100)\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "\n",
        "        # Print Expected Features\n",
        "        print(f\"Expected features for {sector}: {features}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {sector}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDe4NcURG1yA",
        "outputId": "cdbd8106-96e9-45e1-c236-951b29feb083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating SHAP explainability for Agriculture sector...\n",
            "SHAP values saved for Agriculture in shap_values_Agriculture.pkl\n",
            "\n",
            "Generating SHAP explainability for Industrial sector...\n",
            "SHAP values saved for Industrial in shap_values_Industrial.pkl\n",
            "\n",
            "Generating SHAP explainability for IT sector...\n",
            "SHAP values saved for IT in shap_values_IT.pkl\n",
            "\n",
            "Generating SHAP explainability for Manufacturing sector...\n",
            "SHAP values saved for Manufacturing in shap_values_Manufacturing.pkl\n",
            "\n",
            "Generating SHAP explainability for Residential sector...\n",
            "SHAP values saved for Residential in shap_values_Residential.pkl\n",
            "\n",
            "Generating SHAP explainability for Transport sector...\n",
            "SHAP values saved for Transport in shap_values_Transport.pkl\n",
            "\n",
            "Generating SHAP explainability for Power sector...\n",
            "SHAP values saved for Power in shap_values_Power.pkl\n",
            "\n",
            "SHAP explainability generated and saved for all sectors.\n"
          ]
        }
      ],
      "source": [
        "import shap\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import os\n",
        "\n",
        "# List of sector-wise dataset files\n",
        "dataset_files = {\n",
        "    \"Agriculture\": \"agriculture_modified_data.csv\",\n",
        "    \"Industrial\": \"industrial_modified_data.csv\",\n",
        "    \"IT\": \"it_modified_data.csv\",\n",
        "    \"Manufacturing\": \"manufacturing_modified_data.csv\",\n",
        "    \"Residential\": \"residential_modified_data.csv\",\n",
        "    \"Transport\": \"transport_modified_data.csv\",\n",
        "    \"Power\": \"power_modified_data.csv\"\n",
        "}\n",
        "\n",
        "shap_values_dict = {}\n",
        "\n",
        "for sector, file_path in dataset_files.items():\n",
        "    try:\n",
        "        print(f\"\\nGenerating SHAP explainability for {sector} sector...\")\n",
        "\n",
        "        # Load dataset\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        if \"emissions_tons\" not in df.columns:\n",
        "            print(f\"Error: 'emissions_tons' column missing in {sector} dataset.\")\n",
        "            continue\n",
        "\n",
        "        # Load trained XGBoost model\n",
        "        model_filename = f\"xgb_model_{sector}.pkl\"\n",
        "        if not os.path.exists(model_filename):\n",
        "            print(f\"Trained model not found for {sector}, skipping SHAP analysis.\")\n",
        "            continue\n",
        "\n",
        "        xgb_model = joblib.load(model_filename)\n",
        "\n",
        "        # Load the feature scaler\n",
        "        scaler_X = joblib.load(f\"scaler_{sector}.pkl\")\n",
        "\n",
        "        # Extract sector-specific features\n",
        "        sector_features = [col for col in df.columns if col != \"emissions_tons\"]\n",
        "        X = scaler_X.transform(df[sector_features])\n",
        "\n",
        "        # SHAP Explainer\n",
        "        explainer = shap.Explainer(xgb_model)\n",
        "        shap_values = explainer(X)\n",
        "\n",
        "        # Save SHAP values\n",
        "        shap_file = f\"shap_values_{sector}.pkl\"\n",
        "        joblib.dump(shap_values, shap_file)\n",
        "        shap_values_dict[sector] = shap_values\n",
        "\n",
        "        print(f\"SHAP values saved for {sector} in {shap_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {sector}: {e}\")\n",
        "\n",
        "# Final Message\n",
        "print(\"\\nSHAP explainability generated and saved for all sectors.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGqzS-YkFYaW",
        "outputId": "1c0c0b9e-73f1-4500-df3f-681ad05fb307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m132.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.44.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtrsW4HqHt4N",
        "outputId": "88a363c2-d0b4-4a53-996e-8890eceef464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrXbusePHnNw"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mhZ6efZdHzC6"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install streamlit pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDrCZK5KIO1E",
        "outputId": "bafb7e1a-9031-41ee-e44e-80967f611c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit pandas numpy joblib xgboost shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "omNBZ6cPByq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f150f89d-94ad-4586-9e62-b374bb147edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import shap\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of sector-wise models and scalers\n",
        "dataset_files = {\n",
        "    \"Agriculture\": \"agriculture_modified_data.csv\",\n",
        "    \"Industrial\": \"industrial_modified_data.csv\",\n",
        "    \"IT\": \"it_modified_data.csv\",\n",
        "    \"Manufacturing\": \"manufacturing_modified_data.csv\",\n",
        "    \"Residential\": \"residential_modified_data.csv\",\n",
        "    \"Transport\": \"transport_modified_data.csv\",\n",
        "    \"Power\": \"power_modified_data.csv\"\n",
        "}\n",
        "\n",
        "st.title(\"Carbon Footprint Prediction App\")\n",
        "sector = st.selectbox(\"Select a sector:\", list(dataset_files.keys()))\n",
        "\n",
        "if sector:\n",
        "    # Load trained XGBoost model and scalers\n",
        "    xgb_model = joblib.load(f\"xgb_model_{sector}.pkl\")\n",
        "    scaler_X = joblib.load(f\"scaler_{sector}.pkl\")\n",
        "    scaler_y = joblib.load(f\"scaler_y_{sector}.pkl\")\n",
        "    df = pd.read_csv(dataset_files[sector])\n",
        "    sector_features = [col for col in df.columns if col != \"emissions_tons\"]\n",
        "\n",
        "    st.subheader(f\"Input features for {sector}:\")\n",
        "    user_input = {}\n",
        "    for feature in sector_features:\n",
        "        user_input[feature] = st.number_input(f\"{feature}\", min_value=0.0, format=\"%.2f\")\n",
        "\n",
        "    if st.button(\"Predict Carbon Footprint\"):\n",
        "        input_df = pd.DataFrame([user_input])\n",
        "        X_scaled = scaler_X.transform(input_df)\n",
        "        prediction = xgb_model.predict(X_scaled)\n",
        "        predicted_emissions = scaler_y.inverse_transform(prediction.reshape(-1, 1))[0][0]\n",
        "        st.success(f\"Predicted Carbon Footprint: {predicted_emissions:.2f} tons\")\n",
        "\n",
        "        # SHAP explainability\n",
        "        explainer = shap.Explainer(xgb_model)\n",
        "        shap_values = explainer(X_scaled)\n",
        "\n",
        "        st.subheader(\"Feature Contribution (SHAP Values)\")\n",
        "        shap_fig, ax = plt.subplots()\n",
        "        shap.summary_plot(shap_values, X_scaled, feature_names=sector_features, show=False)\n",
        "        st.pyplot(shap_fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0iZDxOgBy29"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# List of sector-wise model files\n",
        "sectors = [\"Agriculture\", \"Industrial\", \"IT\", \"Manufacturing\", \"Residential\", \"Transport\", \"Power\"]\n",
        "\n",
        "for sector in sectors:\n",
        "    try:\n",
        "        # Load trained models\n",
        "        xgb_model = joblib.load(f\"xgb_model_{sector}.pkl\")\n",
        "        scaler_X = joblib.load(f\"scaler_{sector}.pkl\")\n",
        "        scaler_y = joblib.load(f\"scaler_y_{sector}.pkl\")\n",
        "\n",
        "        # Save models and scalers\n",
        "        joblib.dump(xgb_model, f\"xgb_model_{sector}.pkl\")\n",
        "        joblib.dump(scaler_X, f\"scaler_X_{sector}.pkl\")\n",
        "        joblib.dump(scaler_y, f\"scaler_y_{sector}.pkl\")\n",
        "\n",
        "        print(f\"Saved models and scalers for {sector}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {sector}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZEYCCsc5By6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c99900-260b-4ad7-d819-cd5ac5360a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define available sectors\n",
        "sectors = [\"Agriculture\", \"Industrial\", \"IT\", \"Manufacturing\", \"Residential\", \"Transport\", \"Power\"]\n",
        "\n",
        "st.title(\"Carbon Footprint Prediction App\")\n",
        "st.sidebar.header(\"User Input\")\n",
        "\n",
        "# Select sector\n",
        "sector = st.sidebar.selectbox(\"Select Sector\", sectors)\n",
        "\n",
        "# Load necessary models and scalers\n",
        "xgb_model = joblib.load(f\"xgb_model_{sector}.pkl\")\n",
        "scaler_X = joblib.load(f\"scaler_X_{sector}.pkl\")\n",
        "scaler_y = joblib.load(f\"scaler_y_{sector}.pkl\")\n",
        "shap_values = joblib.load(f\"shap_values_{sector}.pkl\")\n",
        "\n",
        "# Load sector-specific features\n",
        "feature_names = scaler_X.feature_names_in_\n",
        "user_input = {}\n",
        "\n",
        "for feature in feature_names:\n",
        "    user_input[feature] = st.sidebar.number_input(f\"{feature}\", value=0.0)\n",
        "\n",
        "# Convert user input to dataframe\n",
        "input_df = pd.DataFrame([user_input])\n",
        "scaled_input = scaler_X.transform(input_df)\n",
        "\n",
        "# Predict emissions\n",
        "prediction = xgb_model.predict(scaled_input)\n",
        "predicted_emissions = scaler_y.inverse_transform(prediction.reshape(-1, 1))[0][0]\n",
        "\n",
        "st.write(f\"### Predicted Carbon Footprint for {sector} Sector: {predicted_emissions:.2f} tons\")\n",
        "\n",
        "# SHAP Explanation\n",
        "st.write(\"## SHAP Explainability\")\n",
        "explainer = shap.Explainer(xgb_model)\n",
        "shap_values = explainer(scaled_input)\n",
        "fig, ax = plt.subplots()\n",
        "shap.waterfall_plot(shap.Explanation(values=shap_values.values[0], base_values=shap_values.base_values[0], feature_names=feature_names), max_display=10)\n",
        "st.pyplot(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u_JArwKFQ-Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1c25c05-0657-4002-b4ae-3c4379c35e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define available sectors\n",
        "sectors = [\"Agriculture\", \"Industrial\", \"IT\", \"Manufacturing\", \"Residential\", \"Transport\", \"Power\"]\n",
        "\n",
        "st.title(\"Carbon Footprint Prediction & Reduction Strategies\")\n",
        "st.sidebar.header(\"User Input\")\n",
        "\n",
        "# Select sector\n",
        "sector = st.sidebar.selectbox(\"Select Sector\", sectors)\n",
        "\n",
        "# Load models and scalers\n",
        "xgb_model = joblib.load(f\"xgb_model_{sector}.pkl\")\n",
        "scaler_X = joblib.load(f\"scaler_{sector}.pkl\")\n",
        "scaler_y = joblib.load(f\"scaler_y_{sector}.pkl\")\n",
        "shap_values = joblib.load(f\"shap_values_{sector}.pkl\")\n",
        "\n",
        "# Get feature names from trained scaler\n",
        "feature_names = scaler_X.feature_names_in_\n",
        "\n",
        "# User Input Features\n",
        "user_input = {}\n",
        "st.sidebar.write(\"### Adjust Input Features:\")\n",
        "for feature in feature_names:\n",
        "    user_input[feature] = st.sidebar.number_input(feature, value=None, placeholder=\"Enter value\")\n",
        "\n",
        "# Predict Button\n",
        "if st.sidebar.button(\"Predict Carbon Footprint\"):\n",
        "    if None in user_input.values():\n",
        "        st.warning(\"Please enter values for all input features.\")\n",
        "    else:\n",
        "        # Convert user input to dataframe\n",
        "        input_df = pd.DataFrame([user_input])\n",
        "\n",
        "        # Scale input features\n",
        "        scaled_input = scaler_X.transform(input_df)\n",
        "\n",
        "        # Predict emissions\n",
        "        prediction = xgb_model.predict(scaled_input)\n",
        "        predicted_emissions = scaler_y.inverse_transform(prediction.reshape(-1, 1))[0][0]\n",
        "\n",
        "        st.write(f\"## Predicted Carbon Footprint for {sector}: {predicted_emissions:.2f} tons\")\n",
        "\n",
        "        # SHAP Explainability\n",
        "        st.write(\"## SHAP Explainability\")\n",
        "        explainer = shap.Explainer(xgb_model)\n",
        "        shap_values = explainer(scaled_input)\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        shap.waterfall_plot(\n",
        "            shap.Explanation(values=shap_values.values[0], base_values=shap_values.base_values[0], feature_names=feature_names),\n",
        "            max_display=10\n",
        "        )\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Carbon Footprint Reduction Strategies\n",
        "        st.write(\"## Reduction Strategies\")\n",
        "\n",
        "        recommendations = {\n",
        "            \"Agriculture\": \"Optimize fertilizer usage, adopt precision irrigation, and improve livestock feed efficiency.\",\n",
        "            \"Industrial\": \"Upgrade to energy-efficient machinery, use recycled materials, and minimize process waste.\",\n",
        "            \"IT\": \"Shift to energy-efficient data centers, optimize cooling systems, and prioritize cloud energy savings.\",\n",
        "            \"Manufacturing\": \"Enhance machine efficiency, reduce material waste, and implement smart energy monitoring.\",\n",
        "            \"Residential\": \"Adopt energy-efficient appliances, use solar power, and reduce water & gas consumption.\",\n",
        "            \"Transport\": \"Switch to EVs/hybrids, improve fuel efficiency, and optimize travel routes.\",\n",
        "            \"Power\": \"Increase renewable energy usage, improve grid efficiency, and reduce coal dependency.\"\n",
        "        }\n",
        "\n",
        "        st.write(f\"**{recommendations[sector]}**\")\n",
        "\n",
        "        st.write(\"### Suggested Actions:\")\n",
        "        for feature, value in user_input.items():\n",
        "            st.write(f\"➡ Optimize {feature} to lower emissions.\")\n",
        "\n",
        "        st.write(\"Implementing these strategies can help reduce your carbon footprint!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00vZvOHlWrOv",
        "outputId": "43bbe452-5116-428c-84d8-15ef56bb593c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import google.generativeai as genai  # Import Gemini chatbot API\n",
        "\n",
        "# Set up Gemini API (Replace \"YOUR_GEMINI_API_KEY\" with your actual API key)\n",
        "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")\n",
        "chatbot = genai.GenerativeModel(\"gemini-pro\")\n",
        "\n",
        "# Define available sectors\n",
        "sectors = [\"Agriculture\", \"Industrial\", \"IT\", \"Manufacturing\", \"Residential\", \"Transport\", \"Power\"]\n",
        "\n",
        "# Feature thresholds for reduction suggestions\n",
        "feature_thresholds = {\n",
        "    \"Agriculture\": {\n",
        "        \"energy_usage_mwh\": 50,\n",
        "        \"crop_yield_tons\": 100,\n",
        "        \"fertilizer_use_kg\": 200,\n",
        "        \"livestock_count\": 500,\n",
        "        \"irrigation_water_liters\": 100000,\n",
        "        \"land_area_hectares\": 1000,\n",
        "    },\n",
        "    \"Industrial\": {\n",
        "        \"energy_usage_mwh\": 500,\n",
        "        \"raw_material_consumption_tons\": 1000,\n",
        "        \"machine_operating_hours\": 2000,\n",
        "        \"industrial_waste_generated_tons\": 100,\n",
        "        \"factory_size_sq_m\": 5000,\n",
        "        \"carbon_capture_tech_usage\": 50,\n",
        "    },\n",
        "    \"IT\": {\n",
        "        \"server_energy_usage_mwh\": 200,\n",
        "        \"data_center_size_sq_m\": 1000,\n",
        "        \"electronic_waste_generated_kg\": 500,\n",
        "    },\n",
        "    \"Manufacturing\": {\n",
        "        \"energy_usage_mwh\": 600,\n",
        "        \"production_output_tons\": 5000,\n",
        "        \"industrial_waste_generated_tons\": 150,\n",
        "        \"water_usage_liters\": 500000,\n",
        "    },\n",
        "    \"Residential\": {\n",
        "        \"electricity_usage_kwh\": 1000,\n",
        "        \"gas_consumption_cubic_m\": 500,\n",
        "        \"waste_generated_kg\": 300,\n",
        "    },\n",
        "    \"Transport\": {\n",
        "        \"fuel_consumption_liters\": 10000,\n",
        "        \"distance_traveled_km\": 50000,\n",
        "        \"fleet_size\": 100,\n",
        "    },\n",
        "    \"Power\": {\n",
        "        \"coal_usage_tons\": 500,\n",
        "        \"renewable_energy_percentage\": 20,\n",
        "        \"emissions_intensity_kg_per_mwh\": 300,\n",
        "    },\n",
        "}\n",
        "\n",
        "st.title(\"Carbon Footprint Prediction & Reduction Strategies\")\n",
        "st.sidebar.header(\"User Input\")\n",
        "\n",
        "# Select sector\n",
        "sector = st.sidebar.selectbox(\"Select Sector\", sectors)\n",
        "\n",
        "# Load necessary models and scalers\n",
        "xgb_model = joblib.load(f\"xgb_model_{sector}.pkl\")\n",
        "scaler_X = joblib.load(f\"scaler_X_{sector}.pkl\")\n",
        "scaler_y = joblib.load(f\"scaler_y_{sector}.pkl\")\n",
        "shap_values = joblib.load(f\"shap_values_{sector}.pkl\")\n",
        "\n",
        "# Load sector-specific features\n",
        "feature_names = scaler_X.feature_names_in_\n",
        "user_input = {}\n",
        "user_provided_input = False  # Track if user has provided any input\n",
        "\n",
        "for feature in feature_names:\n",
        "    user_value = st.sidebar.number_input(f\"{feature}\", value=0.0)\n",
        "    user_input[feature] = user_value\n",
        "    if user_value != 0.0:\n",
        "        user_provided_input = True  # Mark as true if any input is given\n",
        "\n",
        "# Convert user input to dataframe\n",
        "input_df = pd.DataFrame([user_input])\n",
        "\n",
        "# Ensure prediction only runs when user provides input\n",
        "if user_provided_input:\n",
        "    scaled_input = scaler_X.transform(input_df)\n",
        "\n",
        "    # Predict emissions\n",
        "    prediction = xgb_model.predict(scaled_input)\n",
        "    predicted_emissions = scaler_y.inverse_transform(prediction.reshape(-1, 1))[0][0]\n",
        "\n",
        "    st.write(f\"### Predicted Carbon Footprint for {sector} Sector: {predicted_emissions:.2f} tons\")\n",
        "\n",
        "    # Reduction Strategies\n",
        "    st.write(\"## Reduction Strategies\")\n",
        "    suggested_actions = []\n",
        "    thresholds = feature_thresholds.get(sector, {})\n",
        "\n",
        "    for feature, value in user_input.items():\n",
        "        if feature in thresholds and value > thresholds[feature]:\n",
        "            suggested_actions.append(f\"➡ Reduce {feature} (current: {value}, recommended: ≤ {thresholds[feature]})\")\n",
        "            suggested_actions.append(\"🔹 Possible Actions:\")\n",
        "            suggested_actions.append(\"   - Use energy-efficient equipment\")\n",
        "            suggested_actions.append(\"   - Optimize production schedules\")\n",
        "            suggested_actions.append(\"   - Implement waste reduction techniques\")\n",
        "            suggested_actions.append(\"   - Utilize renewable energy sources\")\n",
        "\n",
        "    if suggested_actions:\n",
        "        st.write(\"### Suggested Actions:\")\n",
        "        for action in suggested_actions:\n",
        "            st.write(action)\n",
        "    else:\n",
        "        st.write(\"✅ Your inputs are within optimal limits!\")\n",
        "\n",
        "    # SHAP Explanation\n",
        "    st.write(\"## SHAP Explainability\")\n",
        "    explainer = shap.Explainer(xgb_model)\n",
        "    shap_values = explainer(scaled_input)\n",
        "    fig, ax = plt.subplots()\n",
        "    shap.waterfall_plot(shap.Explanation(values=shap_values.values[0], base_values=shap_values.base_values[0], feature_names=feature_names), max_display=10)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Gemini Chatbot for Further Advice\n",
        "    st.write(\"## Ask Gemini AI for More Insights\")\n",
        "    user_query = st.text_input(\"Ask for additional carbon footprint reduction strategies:\")\n",
        "\n",
        "    if st.button(\"Ask Gemini\"):\n",
        "        response = chatbot.generate_content([user_query])\n",
        "        st.write(\"### Gemini AI Response:\")\n",
        "        st.write(response.text)\n",
        "\n",
        "else:\n",
        "    st.write(\"🔹 Please provide input values to generate predictions.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsGhbCn6JdYU",
        "outputId": "c3be23aa-2e6b-4811-f185-27c8ea0d5c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.105.36.66:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://wet-numbers-do.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlV3FVDiBy_x",
        "outputId": "08d9ec3e-0d5b-4f3e-fca1-e5700e73a50c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.105.36.66:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & sleep 5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}